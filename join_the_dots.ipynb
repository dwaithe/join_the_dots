{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join the Dots - Part A.\n",
    "For a overview guide to what is happening here, please visit: https://youtu.be/Smw3suzynho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Functions and dependencies\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab as plt\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from ijroi.ij_roi import Roi\n",
    "from ijroi.ijpython_decoder import decode_ij_roi\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imageio\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment, tostring\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "\n",
    "def compare_dist(dist_x0,dist_y0,dist_x1,dist_y1):\n",
    "\n",
    "    dist_x0 = dist_x0.astype(np.float32)\n",
    "    dist_y0 = dist_y0.astype(np.float32)\n",
    "    dist_x1 = dist_x1.astype(np.float32)\n",
    "    dist_y1 = dist_y1.astype(np.float32)\n",
    "   \n",
    "    m_x0 = np.tile(dist_x0, (dist_x1.shape[0],1)).astype(np.float)\n",
    "    m_x1 = np.tile(dist_x1, (dist_x0.shape[0],1)).astype(np.float)\n",
    "    m_y0 = np.tile(dist_y0, (dist_y1.shape[0],1)).astype(np.float)\n",
    "    m_y1 = np.tile(dist_y1, (dist_y0.shape[0],1)).astype(np.float)\n",
    "    m_x2 = m_x0-m_x1.T; m_y2 = m_y0-m_y1.T\n",
    "\n",
    "    dist = np.sqrt(m_x2**2+m_y2**2)\n",
    "    mlim = np.min(dist.shape)\n",
    "    dist[np.arange(0,mlim),np.arange(0,mlim)] = 9999\n",
    "\n",
    "    return dist\n",
    "\n",
    "def return_regs_from_img_and_sub(input_path, filename,onlyfile_sections,plot_img=False):\n",
    "    regions = []\n",
    "\n",
    "\n",
    "    output_secs =[]\n",
    "    #opens large image.\n",
    "    output, names,img = decode_roi(input_path+filename)\n",
    "    if plot_img == True:\n",
    "        plt.figure(figsize=(16,16))\n",
    "        plt.imshow(img)\n",
    "        for out in output:\n",
    "            x = out[0]\n",
    "            y = out[1]\n",
    "            w = out[2]\n",
    "            h = out[3]\n",
    "            plt.plot([x,x+w,x+w,x,x],[y,y,y+h,y+h,y],'b')\n",
    "            regions.append([x,y,w,h,\"region\"])\n",
    "    else:\n",
    "        for out in output:\n",
    "            x = out[0]\n",
    "            y = out[1]\n",
    "            w = out[2]\n",
    "            h = out[3]\n",
    "            regions.append([x,y,w,h,\"region\"])\n",
    "\n",
    "\n",
    "    output_index = []\n",
    "    output_coords = []\n",
    "    #Goes through small sections.\n",
    "    for sections in onlyfile_sections:\n",
    "        #If section is in filename.\n",
    "        #print(sections)\n",
    "        if filename == sections[0:filename.__len__()]:\n",
    "            #Decode roi.\n",
    "            outs, names_sects,null = decode_roi(input_path_sections+sections)\n",
    "\n",
    "            seq_num = []\n",
    "            seq_x = []\n",
    "\n",
    "            for out,name in zip(outs,names_sects):\n",
    "                x = out[0]+float(sections.split(\"_\")[4])-null.shape[1]//2\n",
    "                y = out[1]+float(sections.split(\"_\")[5].split(\".\")[0])-null.shape[0]//2\n",
    "                w = out[2]\n",
    "                h = out[3]\n",
    "                n = name\n",
    "                if n == 'f':\n",
    "                    seq_num =[]\n",
    "                    seq_x =[]\n",
    "                    if plot_img == True:\n",
    "                        plt.plot([x,x+w,x+w,x,x],[y,y,y+h,y+h,y],'r')\n",
    "                    continue;\n",
    "                if plot_img == True:\n",
    "                    plt.plot([x,x+w,x+w,x,x],[y,y,y+h,y+h,y],'g')\n",
    "                regions.append([x,y,w,h,name])\n",
    "                try:\n",
    "\n",
    "                    seq_num.append(int(n))\n",
    "                    seq_x.append(x)\n",
    "                except:\n",
    "                    dotx = x\n",
    "                    doty = y\n",
    "\n",
    "            indi = np.argsort(np.array(seq_x))\n",
    "            sortd = np.array(seq_num)[indi]\n",
    "            try:\n",
    "                output_index.append(np.array(\"\".join(sortd.astype(str))).astype(np.int))\n",
    "                output_coords.append([dotx,doty])\n",
    "            except:\n",
    "                pass\n",
    "    indi = np.argsort(np.array(output_index))\n",
    "    sortd_index = np.array(output_index)[indi]\n",
    "    sortd_coords = np.array(output_coords)[indi]\n",
    "    stt_ind = 0\n",
    "    end_ind = 1\n",
    "    for i in range(1,sortd_index.shape[0]):\n",
    "        if sortd_index[i]-sortd_index[i-1] < 3:\n",
    "            continue\n",
    "        else:\n",
    "            end_ind = np.copy(i)\n",
    "            #plt.plot(sortd_coords[stt_ind:end_ind,0],sortd_coords[stt_ind:end_ind,1],'r')\n",
    "            stt_ind = np.copy(end_ind)\n",
    "    #plt.plot(sortd_coords[stt_ind:i,0],sortd_coords[stt_ind:i,1],'r')\n",
    "    return img, regions\n",
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"\\t\")\n",
    "def decode_roi(filepath):\n",
    "    overlay_arr = []\n",
    "    names = []\n",
    "    output = []\n",
    "\n",
    "    if filepath.split(\".\")[-1]== \"tif\":\n",
    "        tfile = tifffile.TiffFile(filepath)\n",
    "        img = tfile.asarray()\n",
    "        img_shape = tfile.asarray().shape[0:2]\n",
    "\n",
    "        if 'Overlays' in tfile.imagej_metadata:\n",
    "            overlays = tfile.imagej_metadata['Overlays']\n",
    "            if overlays.__class__.__name__ == 'list':\n",
    "                #Multiple overlays and so iterate.\n",
    "                for overlay in overlays:\n",
    "\n",
    "                    overlay_arr.append(decode_ij_roi(overlay,img_shape))\n",
    "        #plt.imshow(img)\n",
    "        for i in range(0,overlay_arr.__len__()):\n",
    "\n",
    "            if overlay_arr[i] != False:\n",
    "                x0 = int(overlay_arr[i].x)\n",
    "                y0 = int(overlay_arr[i].y)\n",
    "                wid = int(overlay_arr[i].width)\n",
    "                hei = int(overlay_arr[i].height)\n",
    "                name = overlay_arr[i].name\n",
    "                #plt.plot([x0,x0+wid,x0+wid,x0,x0],[y0,y0,y0+hei,y0+hei,y0])\n",
    "                output.append([x0,y0,wid,hei])\n",
    "                names.append(name.replace('\\x00',''))\n",
    "        return output, names,img\n",
    "class Graph: \n",
    "      \n",
    "    # init function to declare class variables \n",
    "    def __init__(self,V): \n",
    "        self.V = V \n",
    "        self.adj = [[] for i in range(V)] \n",
    "  \n",
    "    def DFSUtil(self, temp, v, visited): \n",
    "  \n",
    "        # Mark the current vertex as visited \n",
    "        visited[v] = True\n",
    "  \n",
    "        # Store the vertex to list \n",
    "        temp.append(v) \n",
    "  \n",
    "        # Repeat for all vertices adjacent f\n",
    "        # to this vertex v \n",
    "        for i in self.adj[v]: \n",
    "            if visited[i] == False: \n",
    "                  \n",
    "                # Update the list \n",
    "                temp = self.DFSUtil(temp, i, visited) \n",
    "        return temp \n",
    "  \n",
    "    # method to add an undirected edge \n",
    "    def addEdge(self, v, w): \n",
    "        self.adj[v].append(w) \n",
    "        self.adj[w].append(v) \n",
    "  \n",
    "    # Method to retrieve connected components \n",
    "    # in an undirected graph \n",
    "    def connectedComponents(self): \n",
    "        visited = [] \n",
    "        cc = [] \n",
    "        for i in range(self.V): \n",
    "            visited.append(False) \n",
    "        for v in range(self.V): \n",
    "            if visited[v] == False: \n",
    "                temp = [] \n",
    "                cc.append(self.DFSUtil(temp, v, visited)) \n",
    "        return cc \n",
    "def generate_xml(xml_file, img_shape, passed_regs):\n",
    "\n",
    "    top = Element('annotation')\n",
    "    folder = SubElement(top, 'folder')\n",
    "    folder.text = 'dc2020'\n",
    "    filename = SubElement(top, 'filename')\n",
    "    filename.text = xml_file.split(\"/\")[-1]\n",
    "\n",
    "    source = SubElement(top, 'source')\n",
    "    database = SubElement(source,'database')\n",
    "    database.text = \"The 2020 dot-to-dot\"\n",
    "    annotation = SubElement(source,'annotation')\n",
    "    annotation.text = \"Waithe 2020\"\n",
    "    image = SubElement(source,'image')\n",
    "    image.text = \"photo\"\n",
    "    size = SubElement(top, 'size')\n",
    "    width = SubElement(size,'width')\n",
    "    width.text = str(img_shape[1])\n",
    "    height = SubElement(size,'height')\n",
    "    height.text = str(img_shape[0])\n",
    "    depth = SubElement(size,'depth')\n",
    "    depth.text = str(img_shape[2])\n",
    "    \n",
    "    for reg in passed_regs:\n",
    "        objects = SubElement(top, 'object')\n",
    "        names = SubElement(objects,'name')\n",
    "        names.text = reg[4]\n",
    "        pose = SubElement(objects,'pose')\n",
    "        pose.text = \"Unspecified\"\n",
    "        truncated = SubElement(objects,'truncated')\n",
    "        truncated.text = \"0\"\n",
    "        difficult = SubElement(objects,'difficult')\n",
    "        difficult.text = \"0\"\n",
    "        bndbox = SubElement(objects, 'bndbox')\n",
    "        xmin = SubElement(bndbox,\"xmin\")\n",
    "        xmin.text = str(int(reg[0]))\n",
    "        ymin = SubElement(bndbox,\"ymin\")\n",
    "        ymin.text = str(int(reg[1]))\n",
    "        xmax = SubElement(bndbox,\"xmax\")\n",
    "        xmax.text = str(int(reg[0]+reg[2]))\n",
    "        ymax = SubElement(bndbox,\"ymax\")\n",
    "        ymax.text = str(int(reg[1]+reg[3]))\n",
    "\n",
    "    f = open(xml_file,'w')\n",
    "    f.write(prettify(top))\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def save_regions_pascal(img,regions,net_input,bin_factor,output_file_img_root,output_file_xml_root,count,plot_on=False):\n",
    "    img_ = img[::bin_factor,::bin_factor,:]\n",
    "    for c in range(0,img_.shape[0]-net_input,net_input):\n",
    "        for r in range(0,img_.shape[1]-net_input,net_input):\n",
    "            im_ = img_[c:c+net_input,r:r+net_input,:]\n",
    "            if plot_on == True:\n",
    "                plt.figure()\n",
    "                plt.imshow(im_)\n",
    "            passed = 0\n",
    "            passed_regs = []\n",
    "            for reg in regions:\n",
    "                x = reg[0]//bin_factor\n",
    "                y = reg[1]//bin_factor\n",
    "                w = reg[2]//bin_factor\n",
    "                h = reg[3]//bin_factor\n",
    "                n = reg[4]\n",
    "                if y > c and y < c+net_input and x > r and x < r+net_input:\n",
    "                    if n == 'region':\n",
    "                        passed +=1\n",
    "                        passed_regs.append([x-r,y-c,w,h,n])\n",
    "                        if plot_on == True:\n",
    "                            plt.plot([x-r,x+w-r,x+w-r,x-r,x-r],[y-c,y-c,y+h-c,y+h-c,y-c],'r')\n",
    "            if passed > 0:\n",
    "                count += 1\n",
    "                n = str(count)\n",
    "                cnt = n.zfill(6)\n",
    "                imageio.imsave(output_file_img_root+cnt+\".jpg\",im_)\n",
    "                generate_xml(output_file_xml_root+cnt+\".xml\",im_.shape,passed_regs)\n",
    "    print(\"total_count\",count)\n",
    "    print(\"excessc\",img_.shape[0]-(c+net_input))\n",
    "    print(\"excessr\",img_.shape[1]-(r+net_input))\n",
    "    return count\n",
    "def save_regions_EAST(img,regions,net_input,bin_factor,output_file_img_root,count,plot_on=False):\n",
    "    img_ = img[::bin_factor,::bin_factor,:]\n",
    "    for c in range(0,img_.shape[0]-net_input,net_input):\n",
    "        for r in range(0,img_.shape[1]-net_input,net_input):\n",
    "            im_ = img_[c:c+net_input,r:r+net_input,:]\n",
    "            if plot_on == True:\n",
    "                plt.figure()\n",
    "                plt.imshow(im_)\n",
    "            passed = 0\n",
    "            passed_regs = []\n",
    "            for reg in regions:\n",
    "                \n",
    "                x = reg[0]//bin_factor\n",
    "                y = reg[1]//bin_factor\n",
    "                w = reg[2]//bin_factor\n",
    "                h = reg[3]//bin_factor\n",
    "                n = reg[4]\n",
    "                if y > c and y+h < c+net_input and x > r and x+w < r+net_input:\n",
    "                    if n == 'region':\n",
    "                        passed +=1\n",
    "                        passed_regs.append([x-r,y-c,w,h,n])\n",
    "                        if plot_on == True:\n",
    "                            plt.plot([x-r,x+w-r,x+w-r,x-r,x-r],[y-c,y-c,y+h-c,y+h-c,y-c],'r')\n",
    "            if passed > 0:\n",
    "                count += 1\n",
    "                n = str(count)\n",
    "                cnt = n.zfill(6)\n",
    "                imageio.imsave(output_file_img_root+cnt+\".jpg\",im_)\n",
    "                f = open(output_file_img_root+cnt+\".txt\",'w')\n",
    "                c = 0\n",
    "                for reg in passed_regs:\n",
    "                    line_str = \"\"\n",
    "                    line_str += str(reg[0]) + \",\"\n",
    "                    line_str += str(reg[1]) + \",\"\n",
    "                    line_str += str(reg[0]+reg[2]) + \",\"\n",
    "                    line_str += str(reg[1]) + \",\"\n",
    "                    line_str += str(reg[0]+reg[2]) + \",\"\n",
    "                    line_str += str(reg[1]+reg[3]) + \",\"\n",
    "                    line_str += str(reg[0]) + \",\"\n",
    "                    line_str += str(reg[1]+reg[3]) + \",\"\n",
    "                    line_str += reg[4]\n",
    "                    if c< passed_regs.__len__()-1:\n",
    "                        line_str += \"\\n\"\n",
    "                    f.write(line_str)\n",
    "                    c+=1\n",
    "                f.close()\n",
    "    print(\"total_count\",count)\n",
    "    print(\"excessc\",img_.shape[0]-(c+net_input))\n",
    "    print(\"excessr\",img_.shape[1]-(r+net_input))\n",
    "    return count\n",
    "def resize_it(imi, shape):\n",
    "    laxis = np.max(imi.shape)\n",
    "    padw = (laxis-imi.shape[0])/2\n",
    "    padh = (laxis-imi.shape[1])/2\n",
    "\n",
    "    imb = np.pad(imi[:,:,0], ((int(np.floor(padw)),int(np.ceil(padw))),(int(np.floor(padh)),int(np.ceil(padh)))), 'minimum')\n",
    "\n",
    "    return np.array(Image.fromarray(imb).resize(shape))\n",
    "def rtn_valid_dots(cc,labs,ans,regions):\n",
    "    dot2dot = []\n",
    "    idi = 0\n",
    "    for cc0 in cc:\n",
    "        nh = []\n",
    "        pasd = False\n",
    "        d = None\n",
    "        for b in cc0:\n",
    "            \n",
    "            if ans[labs[b]] == 'f':\n",
    "                #Any fails is not a good sign. Lets leave it.\n",
    "                pasd = False;\n",
    "                break;\n",
    "            if ans[labs[b]] == 'dot' or ans[labs[b]] == 'star' or ans[labs[b]] == 'triangle' :\n",
    "                pasd = True;\n",
    "                d = np.copy(b)\n",
    "            \n",
    "            nh.append([regions[b],d])\n",
    "        if nh.__len__() ==1:\n",
    "            continue\n",
    "        if pasd == True:\n",
    "            #Our cluster has passed.\n",
    "\n",
    "            order = []\n",
    "            number = []\n",
    "            #Now we need to intrepret the number.\n",
    "            for nh0,d in nh:\n",
    "                if nh0[4] == 'dot' or nh0[4] == 'star' or nh0[4] == 'triangle' :\n",
    "                 c_x = nh0[0]+nh0[2]//2\n",
    "                 c_y = nh0[1]+nh0[3]//2\n",
    "                else:\n",
    "                    order.append(nh0[0])\n",
    "                    number.append(nh0[4])\n",
    "            #print(order,number)  \n",
    "            if number !=[]:\n",
    "                indi = np.argsort(order)\n",
    "                \n",
    "                dot2dot.append([int(\"\".join(np.array(number)[indi])),c_x,c_y,idi,d])\n",
    "            \n",
    "        idi +=1\n",
    "    if dot2dot ==[]:\n",
    "        return []\n",
    "    dot2dot = np.array(dot2dot)\n",
    "    \n",
    "    return dot2dot[np.argsort(np.array(dot2dot)[:,0]),:]\n",
    "def rtn_regions(img,plot=False):\n",
    "    gray = 255-cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "    blur = cv2.GaussianBlur(gray,(61,61),30)\n",
    "    filt = gray-blur\n",
    "    filt[filt<0] = 0\n",
    "    \n",
    "    ret3,th3 = cv2.threshold(filt.astype(np.uint8),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)  \n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(th3, connectivity=4)\n",
    "    \n",
    "    if plot == True:\n",
    "       \n",
    "        plt.figure(figsize=(132,16))\n",
    "    regions = []\n",
    "    for reg in stats[1:]:\n",
    "        x = int(reg[0])\n",
    "        y = int(reg[1])\n",
    "        w = int(reg[2])\n",
    "        h = int(reg[3])\n",
    "        \n",
    "        regions.append([x,y,w,h,'region'])\n",
    "        if w*h > 40:\n",
    "            \n",
    "            if plot == True:\n",
    "                plt.plot([x,x+w,x+w,x,x],[y,y,y+h,y+h,y],'-',lw=1)\n",
    "\n",
    "        \n",
    "    if plot == True:\n",
    "        plt.imshow(img)\n",
    "        for reg in regions:\n",
    "            w = reg[2]\n",
    "            h = reg[3]\n",
    "            x = reg[0]\n",
    "            y = reg[1]\n",
    "            plt.plot([x,x+w,x+w,x,x],[y,y,y+h,y+h,y],'-',lw=1)\n",
    "    return regions,th3\n",
    "\n",
    "def ccw(A,B,C):\n",
    "        return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])\n",
    "\n",
    "\n",
    "def line_intersect(line0,line1):\n",
    "    # Return true if line segments AB and CD intersect\n",
    "    (A,B) = line0\n",
    "    (C,D) = line1\n",
    "    return ccw(A,C,D) != ccw(B,C,D) and ccw(A,B,C) != ccw(A,B,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports the training material from folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import numbers from regions.\n",
    "#Training path.\n",
    "input_path_sections = \"images/sections_labels/\"\n",
    "onlyfile_sections = [f for f in listdir(input_path_sections) if isfile(join(input_path_sections, f))]\n",
    "letters = []\n",
    "labels  =[] \n",
    "for filename in onlyfile_sections:\n",
    "    if filename != \".DS_Store\":\n",
    "        output, names,img = decode_roi(input_path_sections+filename)\n",
    "        if output != []:\n",
    "            for out, name in zip(output,names):\n",
    "                #if name != \"f\":\n",
    "                    imi = 255-img[out[1]:out[1]+out[3],out[0]:out[0]+out[2]]\n",
    "                    laxis = np.max(imi.shape)\n",
    "                    padw = (laxis-imi.shape[0])/2\n",
    "                    padh = (laxis-imi.shape[1])/2\n",
    "            \n",
    "                    imb = np.pad(imi[:,:,0], ((int(np.floor(padw)),int(np.ceil(padw))),(int(np.floor(padh)),int(np.ceil(padh)))), 'minimum')\n",
    "                \n",
    "                    im = np.array(Image.fromarray(imb).resize((28,28)))\n",
    "                    letters.append(im)\n",
    "                    labels.append(name)\n",
    "print('data imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data to train mnist style classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "labels_cat = []\n",
    "for lab in labels:\n",
    "    if lab == 'dot':\n",
    "        labels_cat.append('10')\n",
    "    elif lab == \"square\":\n",
    "        labels_cat.append('10')\n",
    "    elif lab == \"star\":\n",
    "        labels_cat.append('10')\n",
    "    elif lab == \"triangle\":\n",
    "        labels_cat.append('10')\n",
    "    elif lab == \"f\":\n",
    "        labels_cat.append('11')\n",
    "    else:\n",
    "        labels_cat.append(lab)\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(letters), np.array(labels_cat), test_size=0.33, shuffle= True)\n",
    "\n",
    "print(X_train.shape)\n",
    "#reshaping\n",
    "#this assumes our data format\n",
    "#For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \n",
    "#\"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape) #X_train shape: (60000, 28, 28, 1)\n",
    "#set number of categories\n",
    "num_category = 12\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_category)\n",
    "y_test = keras.utils.to_categorical(y_test, num_category)\n",
    "\n",
    "\n",
    "##model building\n",
    "\n",
    "num_category = 12\n",
    "model = Sequential()\n",
    "#convolutional layer with rectified linear unit activation\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#randomly turn neurons on and off to improve convergence\n",
    "model.add(Dropout(0.25))\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "model.add(Flatten())\n",
    "#fully connected to get all relevant data\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#one more dropout for convergence' sake :) \n",
    "model.add(Dropout(0.5))\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "model.add(Dense(num_category, activation='softmax'))\n",
    "\n",
    "\n",
    "#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad\n",
    "#categorical ce since we have multiple classes (10) \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "batch_size = 128\n",
    "num_epoch = 20\n",
    "#model training\n",
    "model_log = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "#Can be used to export images used for testing\n",
    "#c = 0\n",
    "#for im in X_test:\n",
    "#    cv2.imwrite(\"examples/\"+str(c)+\".png\",im*255)\n",
    "#    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dot-2-dot script which does the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Evaluate frame of movies.\n",
    "import time\n",
    "import cv2\n",
    "ans = ['0','1','2','3','4','5','6','7','8','9','dot','f']\n",
    "colours = np.random.rand(32,3) #used only for display\n",
    "\n",
    "input_path = \"/Users/dwaithe/Documents/youtube_videos/computerVisionProjects/join_the_dots/images/tiffsInputs/\"\n",
    "output_path = \"/Users/dwaithe/Documents/youtube_videos/computerVisionProjects/join_the_dots/images/scanned_with_lines/\"    \n",
    "\n",
    "for t in range(45,46):\n",
    "    \n",
    "    plot_on = False\n",
    "    t1 = time.time()\n",
    "    n= str(t).zfill(3)\n",
    "    \n",
    "    filename = \"IMG_00\"+str(t)+\".tif\"\n",
    "    filename = \"pc5bbobdi.tiff\"\n",
    "    img = cv2.imread(input_path +filename)\n",
    "    \n",
    "    #This is the main feature finding function.\n",
    "    regions, filt = rtn_regions(img,plot=plot_on)\n",
    "    \n",
    "    \n",
    "    #Here we initiate some things.\n",
    "    ttl_arr =[] #array to hold small image patches of our letters\n",
    "    dist_x = np.zeros((regions.__len__())).astype(np.int32)\n",
    "    dist_y = np.zeros((regions.__len__())).astype(np.int32)\n",
    "    c = 0\n",
    "\n",
    "    for reg in regions:\n",
    "        x,y,w,h,s = reg\n",
    "        #we populate our coordinate matrixes\n",
    "        dist_x[c] = x\n",
    "        dist_y[c] = y\n",
    "        ttl_arr.append(resize_it(255-img[y:y+h,x:x+w,:],(28,28)))\n",
    "        c+=1\n",
    "\n",
    "    probs = model.predict(np.array(ttl_arr).reshape(regions.__len__(),28,28,1))\n",
    "    labs = np.argmax(probs,1)\n",
    "    t2 = time.time()\n",
    "    if plot_on:\n",
    "        plt.figure(figsize = (16,16))\n",
    "        #plt.ylim(1750,1200)\n",
    "        plt.imshow(img)  \n",
    "    \n",
    "    for rgx in np.arange(0,regions.__len__()):\n",
    "        regions[rgx][4] = ans[labs[rgx]]\n",
    "        reg = regions[rgx]\n",
    "        x = int(reg[0])\n",
    "        y = int(reg[1])\n",
    "        w = int(reg[2])\n",
    "        h = int(reg[3])\n",
    "        \n",
    "        #if reg[4] == 'dot':\n",
    "        #    image = cv2.circle(img,(int(x),int(y)),5,(255,255,255),5)\n",
    "        #if plot_on:\n",
    "         #plt.text(x,y,str(ans[labs[rgx]]),c='r')\n",
    "  \n",
    "    t0 = time.time()\n",
    "    X = np.zeros((regions.__len__(),4))\n",
    "\n",
    "    for ct,reg in enumerate(regions):\n",
    "        X[ct,0] = reg[0]+reg[2]//2\n",
    "        X[ct,1] = reg[1]+reg[3]//2\n",
    "        \n",
    "\n",
    "    #Comparing all the non-dots.\n",
    "    dist_dot_dot = compare_dist(X[labs!=10,0],X[labs!=10,1],X[labs!=10,0],X[labs!=10,1])       \n",
    "    lisl = np.where(labs!=10)[0]\n",
    "    pairs =[]\n",
    "    for ct,lab in enumerate(np.where(labs!=10)[0]):\n",
    "        distt = dist_dot_dot[:,ct]\n",
    "        nn = np.argmin(distt)\n",
    "        if np.min(distt)<50:\n",
    "            pairs.append([lisl[ct],lisl[nn]])\n",
    "\n",
    "\n",
    "    #Generate graph to find neighbourhoods.\n",
    "    g = Graph(regions.__len__()); \n",
    "    for nnn in pairs:\n",
    "        g.addEdge(nnn[0], nnn[1])\n",
    "        \n",
    "\n",
    "    #Now we find the nearest dot to each non-dot.\n",
    "    dist_dot_ndot = compare_dist(X[labs==10,0],X[labs==10,1],X[labs!=10,0],X[labs!=10,1])\n",
    "\n",
    "    #nondots vs dots distance matrix calcualtion\n",
    "    lisl = np.where(labs==10)[0]\n",
    "    lisnl = np.where(labs!=10)[0]\n",
    "    pairs =[]\n",
    "    for ct,lab in enumerate(np.where(labs==10)[0]):\n",
    "        distt = dist_dot_ndot[:,ct]\n",
    "        nn = np.argmin(distt)\n",
    "        if np.min(distt)<60:\n",
    "            pairs.append([lisl[ct],lisnl[nn]])\n",
    "\n",
    "\n",
    "    #plot the connections between regions.\n",
    "    for nnn in pairs:\n",
    "        g.addEdge(nnn[0], nnn[1]) \n",
    "    cc = g.connectedComponents()\n",
    "\n",
    "  \n",
    "    #Returns valid dots.\n",
    "    dot2dot = rtn_valid_dots(cc,labs,ans,regions)\n",
    "    dts = np.zeros((X.shape[0]))\n",
    "    if dot2dot != []:\n",
    "        dts[dot2dot[:,4]] = dot2dot[:,0]\n",
    "    dets = np.array((X[labs==10,0],X[labs==10,1],np.array(dts[labs==10]))).T\n",
    "    \n",
    "    order = np.argsort(dets[:,2])\n",
    "    reorgt = dets[order,:]\n",
    "    difv = np.diff(reorgt[:,2])\n",
    "    line_segments = []\n",
    "    for i in range(0,difv.shape[0]):\n",
    "        if difv[i] >0 and difv[i]<4:\n",
    "            if np.sqrt((reorgt[i,0]-reorgt[i+1,0])**2 + (reorgt[i,1]-reorgt[i+1,1])**2):# <150000:\n",
    "                start_point = (int(reorgt[i,0]),int(reorgt[i,1]))\n",
    "                end_point =  (int(reorgt[i+1,0]),int(reorgt[i+1,1]))\n",
    "                \n",
    "                line_segments.append([start_point,end_point])\n",
    "        \n",
    "                \n",
    "    if plot_on:\n",
    "        plt.figure(figsize=(16,16))\n",
    "        plt.imshow(img)\n",
    "    #This is a filter to improve the quality of the output. Line segments shouldn't really overlap.\n",
    "    #If a line segment overlaps more than a few times with other line segments, it should be voided as it is likely wrong.\n",
    "    f = open(output_path+filename.split(\".\")[-2]+'.txt','w')\n",
    "    for l0 in range(0,line_segments.__len__()):\n",
    "        line0 = line_segments[l0]\n",
    "        count_intersect = 0\n",
    "        for l1 in range(0,line_segments.__len__()):\n",
    "            line1 = line_segments[l1]\n",
    "            if l0 != l1:\n",
    "                if line_intersect(line0,line1):\n",
    "                    count_intersect +=1\n",
    "        #This is the number of intersections that a line must make for it to be banned.\n",
    "        #if count_intersect < 5:\n",
    "        if plot_on:\n",
    "            plt.plot([line0[0][0],line0[1][0]],[line0[0][1],line0[1][1]],'b-')\n",
    "        color = (0, 0, 255)            \n",
    "        img = cv2.line(img, line0[0], line0[1], color, 8)\n",
    "        f.writelines(str(line0[0])+\",\"+str(line0[1])+'\\n')\n",
    "            \n",
    "   \n",
    "    imRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(output_path+filename.split(\".\")[-2]+'.png',imRGB)\n",
    "    f.close()\n",
    "    print('time (ms)',time.time()-t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
